{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install --upgrade pip\n",
    "!pip -q install jsonlines\n",
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import jsonlines\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "# Lists all buckets\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bucket = 'INSERT BUCKET HERE'\n",
    "input_prefix = 'Dogs/GermanShepherd'\n",
    "training_input_prefix = f'{input_prefix}/Training'\n",
    "test_input_prefix = f'{input_prefix}/Test'\n",
    "\n",
    "bashurl_bucket = f'https://{top_bucket}.s3.amazonaws.com'\n",
    "s3uri_bucket = f's3://{top_bucket}'\n",
    "bashurl_prefix_bucket = f'{bashurl_bucket}/{input_prefix}/'\n",
    "s3uri_prefix_bucket = f'{s3uri_bucket}/{input_prefix}/'\n",
    "\n",
    "print(bashurl_prefix_bucket)\n",
    "print(s3uri_prefix_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively downloads every file in the path ending in .jpg\n",
    "!aws s3 cp s3://$top_bucket/$training_input_prefix Training/ --include \"*.jpg\" --recursive\n",
    "!aws s3 cp s3://$top_bucket/$test_input_prefix Test/ --include \"*.jpg\" --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "labeling_job_name = 'GermanShepherd'\n",
    "# This is the output of the labeling job, and 'output.manifest' is the file created with\n",
    "# all the S3 locations per image with annotations and meta-data in JSON format.\n",
    "s3_output = client.describe_labeling_job(LabelingJobName=labeling_job_name)['OutputConfig']['S3OutputPath'] + labeling_job_name\n",
    "s3_output_manifest = f'{s3_output}/manifests/output/output.manifest'\n",
    "\n",
    "!aws s3 cp $s3_output_manifest LabelingOutput/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output_manifest(augmented_manifest):\n",
    "    with jsonlines.open(augmented_manifest, 'r') as reader:\n",
    "        lines = list(reader)\n",
    "        print(len(lines), 'images in original output.manifest')\n",
    "        print(\"----------------------------------------------------\")\n",
    "        for each_line in lines:\n",
    "            img_source_ref = each_line['source-ref']\n",
    "            try:\n",
    "                if (len(each_line['GermanShepherd']['annotations'])==0):\n",
    "                    #print(img_source_ref, \"was not annotated and was removed\")\n",
    "                    lines.remove(each_line)\n",
    "                    continue\n",
    "            except KeyError:\n",
    "                #print(img_source_ref, \"failed and was removed\")\n",
    "                lines.remove(each_line)\n",
    "                continue\n",
    "            try:\n",
    "                s3.Object(top_bucket, training_input_prefix + '/' + os.path.basename(img_source_ref)).load()\n",
    "            except botocore.exceptions.ClientError as e:\n",
    "                #print(\"REMOVED\", each_line)\n",
    "                lines.remove(each_line)\n",
    "        print(len(lines), 'images after removal of errors')\n",
    "        reader.close()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_new_manifest(new_manifest_lines, new_manifest):\n",
    "    with open(new_manifest, 'w') as f:\n",
    "        for line in new_manifest_lines:\n",
    "            current_source_ref = line['source-ref']\n",
    "            new_s3_path = current_source_ref[:current_source_ref.rfind('/')] + '/Training/' + os.path.basename(current_source_ref)\n",
    "            line['source-ref'] = new_s3_path\n",
    "            f.write(json.dumps(line))\n",
    "            f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_manifest = 'LabelingOutput/output.manifest'\n",
    "cleaned_lines = clean_output_manifest(augmented_manifest)\n",
    "\n",
    "cleaned_manifest = 'LabelingOutput/cleaned-output.manifest'\n",
    "write_to_new_manifest(cleaned_lines, cleaned_manifest)\n",
    "\n",
    "s3_cleaned_manifest = f'{s3_output}/manifests/output/'\n",
    "!aws s3 cp LabelingOutput/cleaned-output.manifest $s3_cleaned_manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_annotated_images(manifest, num_of_images):\n",
    "    def draw_bounding_boxes(img_path, bboxes):\n",
    "        im = np.array(Image.open(img_path), dtype=np.uint8)\n",
    "        fig,ax = plt.subplots(1)\n",
    "        ax.imshow(im)\n",
    "        colors = cycle(['r', 'g', 'b', 'y', 'c', 'm', 'k', 'w'])\n",
    "        for bbox in bboxes:\n",
    "            rect = patches.Rectangle((bbox['left'],bbox['top']),bbox['width'],bbox['height'],linewidth=1,edgecolor=next(colors),facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        plt.show()\n",
    "    \n",
    "    with jsonlines.open(manifest, 'r') as reader:\n",
    "        for desc in list(reader)[:num_of_images]:\n",
    "            local_path = 'Training/' + os.path.basename(desc['source-ref'])\n",
    "            file_exists = os.path.isfile(local_path)\n",
    "            if (file_exists):\n",
    "                bboxes = desc[labeling_job_name]['annotations']\n",
    "                draw_bounding_boxes(local_path, bboxes)\n",
    "                #print(desc['source-ref'])\n",
    "            else:\n",
    "                print(desc['source-ref'], \"doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_annotated_images(cleaned_manifest, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 0.7\n",
    "\n",
    "np.random.shuffle(cleaned_lines)\n",
    "dataset_size = len(cleaned_lines)\n",
    "num_training_samples = round(dataset_size * training_size)\n",
    "train_data = cleaned_lines[:num_training_samples]\n",
    "validation_data = cleaned_lines[num_training_samples:]\n",
    "\n",
    "training_manifest = 'train.manifest'\n",
    "with open(training_manifest, 'w') as f:\n",
    "    for line in train_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "validation_manifest = 'validation.manifest'\n",
    "with open(validation_manifest, 'w') as f:\n",
    "    for line in validation_data:\n",
    "        f.write(json.dumps(line))\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "print(f'Training samples: {num_training_samples}, Validation samples: {len(cleaned_lines)-num_training_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_training = f'{input_prefix}/training'\n",
    "\n",
    "s3_train_data_path = 's3://{}/{}/{}'.format(top_bucket, prefix_training, training_manifest)\n",
    "s3_validation_data_path = 's3://{}/{}/{}'.format(top_bucket, prefix_training, validation_manifest)\n",
    "\n",
    "!aws s3 cp train.manifest s3://$top_bucket/$prefix_training/\n",
    "!aws s3 cp validation.manifest s3://$top_bucket/$prefix_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = sagemaker.amazon.amazon_estimator.get_image_uri(\n",
    "    boto3.Session().region_name, 'object-detection', repo_version='latest')\n",
    "s3_output_path = 's3://{}/{}/output'.format(top_bucket, prefix_training)\n",
    "\n",
    "# Create unique job name\n",
    "training_job_name = 'dogs-germanshepherd-detection-Cleaned-01'\n",
    "\n",
    "training_params = \\\n",
    "    {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            # Indicates the type of built-in SageMaker algorithm\n",
    "            \"TrainingImage\": training_image,\n",
    "            # Defines how the training algorithm obtains training data.\n",
    "            # With \"File\", the entire dataset has to be downloaded.\n",
    "            # With \"Pipe\", the data is streamed one at a time.\n",
    "            \"TrainingInputMode\": \"Pipe\"\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"OutputDataConfig\": {\n",
    "            # The model artifacts output folder\n",
    "            \"S3OutputPath\": s3_output_path\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": 1,\n",
    "            # For Object Detection, a machine with a GPU is required.\n",
    "            \"InstanceType\": \"ml.p2.xlarge\",\n",
    "            \"VolumeSizeInGB\": 50\n",
    "        },\n",
    "        \"TrainingJobName\": training_job_name,\n",
    "        \"HyperParameters\": {\n",
    "            \"base_network\": \"resnet-50\",\n",
    "            \"use_pretrained_model\": \"1\",\n",
    "            \"num_classes\": \"1\",\n",
    "            \"mini_batch_size\": \"1\",\n",
    "            \"epochs\": \"30\",\n",
    "            \"learning_rate\": \"0.002\",\n",
    "            \"lr_scheduler_step\": \"\",\n",
    "            \"lr_scheduler_factor\": \"0.1\",\n",
    "            \"optimizer\": \"adadelta\",\n",
    "            \"momentum\": \"0.9\",\n",
    "            \"weight_decay\": \"0.0005\",\n",
    "            \"overlap_threshold\": \"0.5\",\n",
    "            \"nms_threshold\": \"0.45\",\n",
    "            \"image_shape\": \"300\",\n",
    "            \"label_width\": \"350\",\n",
    "            \"num_training_samples\": str(num_training_samples)\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 86400\n",
    "        },\n",
    "        \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"AugmentedManifestFile\",  # NB. Augmented Manifest\n",
    "                        \"S3Uri\": s3_train_data_path,\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                        # NB. This must correspond to the JSON field names in your augmented manifest.\n",
    "                        \"AttributeNames\": ['source-ref', 'GermanShepherd']\n",
    "                    }\n",
    "                },\n",
    "                \"ContentType\": \"application/x-recordio\",\n",
    "                \"RecordWrapperType\": \"RecordIO\",\n",
    "                \"CompressionType\": \"None\"\n",
    "            },\n",
    "            {\n",
    "                \"ChannelName\": \"validation\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"AugmentedManifestFile\",  # NB. Augmented Manifest\n",
    "                        \"S3Uri\": s3_validation_data_path,\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                        # NB. This must correspond to the JSON field names in your augmented manifest.\n",
    "                        \"AttributeNames\": ['source-ref', 'GermanShepherd']\n",
    "                    }\n",
    "                },\n",
    "                \"ContentType\": \"application/x-recordio\",\n",
    "                \"RecordWrapperType\": \"RecordIO\",\n",
    "                \"CompressionType\": \"None\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Now we create the SageMaker training job.\n",
    "client = boto3.client(service_name='sagemaker')\n",
    "client.create_training_job(**training_params)\n",
    "\n",
    "# Confirm that the training job has started\n",
    "status = client.describe_training_job(TrainingJobName=training_job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "print(\"Training job status: \", training_info['TrainingJobStatus'])\n",
    "print(\"Secondary status: \", training_info['SecondaryStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name = training_job_name + '-model' + timestamp\n",
    "\n",
    "training_image = training_info['AlgorithmSpecification']['TrainingImage']\n",
    "model_data = training_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "primary_container = {\n",
    "    'Image': training_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = training_job_name + '-epc' + timestamp\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.t2.medium',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = training_job_name + '-ep' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = client.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "test_images = glob.glob('Test/*')\n",
    "print(*test_images, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_bbox_data(image_path, prediction):\n",
    "    class_id, confidence, xmin, ymin, xmax, ymax = prediction\n",
    "    width, height = Image.open(image_path).size\n",
    "    bbox_data = {'class_id': class_id,\n",
    "               'height': (ymax-ymin)*height,\n",
    "               'width': (xmax-xmin)*width,\n",
    "               'left': xmin*width,\n",
    "               'top': ymin*height}\n",
    "    return bbox_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Call SageMaker endpoint to obtain predictions\n",
    "def get_predictions_for_img(runtime_client, endpoint_name, img_path):\n",
    "    with open(img_path, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "\n",
    "    response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                       ContentType='application/x-image', \n",
    "                                       Body=payload)\n",
    "\n",
    "    result = response['Body'].read()\n",
    "    result = json.loads(result)\n",
    "    return result\n",
    "\n",
    "# wait until the status has changed\n",
    "client.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')\n",
    "\n",
    "for test_image in test_images:\n",
    "    result = get_predictions_for_img(runtime_client, endpoint_name, test_image)\n",
    "    confidence_threshold = .5\n",
    "    best_n = 3\n",
    "    # display the best n predictions with confidence > confidence_threshold\n",
    "    predictions = [prediction for prediction in result['prediction'] if prediction[1] > confidence_threshold]\n",
    "    predictions.sort(reverse=True, key = lambda x: x[1])\n",
    "    bboxes = [prediction_to_bbox_data(test_image, prediction) for prediction in predictions[:best_n]]\n",
    "    show_annotated_image(test_image, bboxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
